# Advanced-Machine-Learning

TASK 1: PREDICT THE AGE OF A BRAIN FROM MRI FEATURES
This task is primarily concerned with regression. However, we have perturbed the original MRI features in several ways. You will need to perform outlier detection, feature selection, and other preprocessing to achieve the best result.

Solution:First of all , we got rid of nan value by replacing with the median of each column. It was not possible to simply get rid of the rows/columns with nan values since most them already had some. Secondly, for feature selection ,  We removed 270 features that were uniformly distributed ( More specifically , we removed features that the min and max changed by between 9 and 11%). We then removed the zero variance features. After testing many techniques for features selection ranging from neural networks, Lasso , low variance, etc , we found the best features with  Reccurent features elimination (RFE) with gradient boosting Regressor as estimator , keeping 60 features. The next step was to detect some outliers that would reduce the performance of our models. We used isolation forest to detect the outliers and we were left with 1135 samples.  For training and predictions, We used the weighted average of 3 regression models: Gradient boosting, XGBRegressor and Hist Boosting Regressor.  To fine-tune the parameters , we used simple breadth search. To conclude the project, we used a Voting Regressor for the weight parameters for the averaging. We didn't normalize because it didn't help for the predictions.

TASK 2: DISEASE CLASSIFICATION FROM IMAGE FEATURES
This task is primarily concerned with multi-class classification where you have 3 classes. However, we have changed the original image features in several ways. You will need to deal with class imbalance; in the training set, there are 600 examples from class 0 and 2 but 3600 examples from class 1. Test set has the same class imbalance as the training set.

Solution: Beating the hard baseline score was pretty straight forward, any SVM or normal net would do it. The hard part was to reduce the variance and to do that we chose many averaging methods. At the end we did majority voting for 3 submissions. The first submission was an ensemble of 63 neural nets. We used 3 nets architecture , same number of layers and dropout but different layer sizes and activations. For each of them , we first trained one net that used the provided data + augmented data from label 0 and 2 (we just oversampled). Then we seperated layer 1 in 6 batches and trained the nets for each batches ( so that all label had 600 samples), In total we had 7 nets per net architecture with these training datasets. Finally we saved the nets at 10 ,20 and 30 epochs, so that would give a total of 63 nets. For the second submission, we used stacking for a few normal dense layers net with weighted loss.We seperated the data in 10 fold, trained each model on 9 folds an predicted the 10th fold. Then we used these predictions to train the stacker. The last submission was a simple SVC with RBF kernel and tuned hyperparameters.


TASK 3: HEART RHYTHM CLASSIFICATION FROM RAW ECG SIGNALS
While the previous projects dealt with medical image features, we turn now to the classification of entire time series into one of 4 classes. This time you will work with the original ECG recordings of different length sampled as 300Hz to predict heart rhythm.

Solution: We used a convultional net architecture of 16 layers, consisting of 2 convolutions (same output layers,first with strides of 2. the other with stride of 1), one max pooling, dropout, 2 convolutions, one maxpooling,dropout, one convolution, one maxpooling, dropout, one convolution, global maxpooling and 3 denses. These layers were chosen to reduce the size of the outputs to almost a single layer (to avoid concatenating or too much GlobalMaxPooling), but also without too big layer size. After multiple testings, having an output after the convultions bigger than 256 would give weaker results. All the activations were Relu and the last one was softmax.
Before training, we augmented the data by streching uniformly between [1,1.2] each sample and added the last half of the sample to the first half of it. Then ,we used the same architecture but saved the models from epoch 15 to epoch 20 and used majority voting to create another submission.At the end, we added a version of the signal with some part of it masked with zero and did the same thing as the previous submission to get a third submission. Finally we did majority voting on these three submissions to get the current result. This submission would be ranked number two in the public score, but we chose not the use the best score to avoid overfitting.

TASK 4: SLEEP STAGING FROM EEG/EMG
In this task we will perform sequence classification. We will categorize temporally coherent and uniformly distributed short sections of a long time-series. In particular, for each 4 seconds of a lengthy EEG/EMG measurement of brain activity recorded during sleep, we will assign one of the 3 classes corresponding to the sleep stage present within the evaluated epoch.

Solution: We started by transforming all the time series into spectogram with consecutive fourrier transforms. Then we normalized the data on each frequency. We tried many filtering methods but found out that just a normal bypass filtering of 24 hz gave us the best results. To take advantage of time depedencies between the samples, we decided to add 2 epochs before and after each samples. In other words, we augmented the data by concatenating 2 epochs sample before and after the sample. More than two gave us sub-par results. This might be because the net had some difficulties figuring out which position is the real sample in question. Then, we feeded our augemented and filtered data with one neural network with simple dense layers and dropout. Of course, we weighted the cross-entropy loss function to account for the class imbalance in the data. An interesting discovery was that the cross-validation score would remain the same if only trained on 2 of the 3 patients. To make sure we would get the best BMAC from cross-validation, we used the best 3 trained model during our K-cross validation (in term of BMAC) and used these models to predict on the test set. Finally we did majority voting on these 3 predictions to get the score we have. Finally, we smoothed to get rid of the improbable transitions or points that seem out of place.There was some potentiel with features counting the beta, gamma, alpha waves but the results were not good enough.
